# 3G4 Medical Imaging and Computer Graphics[^1]
[^1]:Created by: Tom Xiaoding  Lu on 01/02/19
## 1. Medical Image Acquisition
### 1.1 Ultrasonic Imaging
#### **Basic Principle**
  * Ultrasound waves are generated by **piezoelectric crystals** which vibrates in an electric field
  * Its vibration when coupled to the patient's skin, spreads to the tissue
  * The vibration spreads to surrounding tissue particles, can be viewed as a propagation longitudinal pressure wave:![Capture](/assets/Capture_g58hgp9um.PNG)
  * The sound waves from a hand-held transducer propagate into the patient undergoing attenuation, diffraction, scattering, refraction and reflection
  * The probe also acts as a detector, the reflected intensity can be plotted against depth resulting in an **A-line** which is a 1D line
  ![Capture](/assets/Capture_tkcnmekc2.PNG)
  * By sweeping the ultrasound beam across a plane, and stacking the **A lines**, a 2D **B-Scan** is constructed with excellent temporal resolution of **70-80 B scans per second**
  ![Capture](/assets/Capture_9nd9a4n49.PNG)
  A: caused by **attenuation**
  S: **Speckle pattern** due to scattering
  R: Clear boundaries caused by **specular reflection and refraction**
#### **Image Construction**
  - **Filtering** removes high frequency noise
  - **Envelope detection** removes the uninteresting radio frequency oscillations
  - **Time gain compensation** corrects for attenuation
  - **Log compression** compensates for large amplitude difference between specular and scatter reflections
  <img src="/assets/Capture_ps3l4qv0g.PNG" width="500">

#### **Doppler Imaging and M Mode Imaging**
  - A Doppler ultrasound is used to estimate the blood flow through your blood vessels  
  - **Pulsed wave (PW)** Doppler measures the velocity at a particular location by **firing a short sequence of pulses along the same line** and looks at the phase differences between the received signals
  - Suffer from inferior spatial and temporal resolution
  - **M-mode imaging**: instead of sweeping the beam across the B-scan plane, a single A-line is scanned repeatedly, generating a 1D image displayed against time
  ![Capture](/assets/Capture_t4oupqc91.PNG)

#### **Adiabatic compressibility:**
The sound speed is given by $c_0 = \sqrt{1/\rho_0\beta_{s0}}$ where $\beta_s$ is the adiabatic compressibility defined as:
$$
\beta_s = \dfrac{1}{\rho}\left(\dfrac{\partial \rho}{\partial p}\right)
$$
Which is the fractional change in density per unit increase in pressure acting on it. **i.e. The easier it is to squish something, the greater its compressibility**, **Ultrasound scanners assume average speed of 1540ms^-2**

#### **Attenuation, Specular reflection and refraction**
  - Attenuation:
    - Mainly due to medium's viscosity which converts acoustic energy to heat
    - If the wave has amplitude $A_z$ and $A_0$ at propogation distances $z, 0$ respectively then:
    $$A_z = A_0 e^{-\alpha z} = A_0 e^{-\alpha_0 f^n z}$$
    - The attenuation coefficient $\alpha$ is therefore $\dfrac{\ln (A_0/A_z)}{z}$
    - At imaging frequencies, most tissues have an $\alpha$ that is proportional to frequency $(n=1)$.
  - Specular reflection and refraction:
    - Consider case below where there is a wave travelling from medium 1 to medium 2:
    <img src="/assets/Capture_fv88vzkck.PNG" width="500">
    Define specific acoustic impedance $Z$ in each material as $$Z_1 = \rho_1c_1 \qquad \qquad Z_2 = \rho_2c_2$$
    - To relate the **power** in the incident, reflected and transmitted waves, the intensity reflection coefficient is $$R = \dfrac{I_r}{I_i} = \left(\dfrac{Z_2-Z_1}{Z_2+Z_1}\right)^2$$
    - The transmission coefficient is $$T = 1-R = \dfrac{4Z_1Z_2}{(Z_2+Z_1)^2}$$
    - Reflection and refraction example, how much of a 1MHz pulse makes it back to the probe, assume a 1cm layer of fat, 3cm of muscle then bone:
    <img src="/assets/Capture_2jc6scnee.PNG" width="500">
    Starting with one unit of intensity, 1cm fat means a drop of 0.63dB hence a factor of $10^{-0.63/10}=0.865$ of the original left.
    Fat to muscle boundary has $T = \dfrac{4\times 1.38 \times 1.70 }{(1.48 + 1.70 )^2} = 0.989$. So, 0.856 of the original is left.
    3cm of muscle at 1.2dB/cm so 3.6dB corresponding to 0.437, so 0.373 of the original is left.
    Muscle to bone has $R = 0.227$ so 0.085 is reflected back
    The 3cm of muscle again causes a drop of 0.437 leaving 0.037 of original intensity
    Keep working backwards, we get in total 0.032 of the original intensity gets back
    ![Capture](/assets/Capture_zyyuxfcz1.PNG)
#### **Axial Resolution**
  - Denote $w$ as the pulse width of the ultrasound, the axial resolution of an ultrasound image is $w/2$
  - This is because we must transmit at least one cycle, $w$ increases with low frequency probes, so low frequency probes have worse axial resolution although penetrates further
#### **Lateral Resolution**
  - A single element transducer usually has a wide field of view, making it impossible do distinguish between these reflectors by using the RF data collected by the transducer.
  - One way is to narrow the field of view to smaller area is through the use of physical lenses
  - A second way is to narrow the field of view is through the use of multiple transducers, fired at once.
  - The RF data collected by each transducer below shows a pulse at a different time, these are called **pre-beam forming RF data**, to focus the recieved data, these pre-beam forming data are shifted in time so the pulses are matched, and signals added
  <img src="/assets/Capture_8xzn42cye.PNG" width="600">
  <img src="/assets/Capture_zkseexi42.PNG" width="600">

   - However, we do not know where the reflector is (otherwise we wouldn't be imaging it). They key is we can focus **the pre beam forming RF data on a specific point in space**, i.e. adjust the delays that correspond to a specific distance. Then any thing that is imaged which is not in focus come up as a blury signal, only things that are in focus have strong signals
   - Ideally we would like to focus the data at all points in the image, one point at a time, focusing the ultrasound data at all points throughout the image is called **dynamic receive focusing** and require high memory, bandwidth and processing ability.
#### **Elevational Resolution**
 <img src="/assets/Capture_jacoc1v1f.PNG" width="450">

#### **Scattering and speckle**
  - Reflections do not only occur at material boundaries, **individual tissues are inhomogeneous**, there are small, local vibrations of density and compressibility which give rise to **scatter reflections which show up as speckle** in B-scans
  - The smallest inhomogeneity is called a point scatter which **transmits the incident wave in all directions**. The waves which head back towards the probe, contributing to the speckle pattern are called backscatter
  <img src="/assets/Capture_jn5tn3k8x.PNG" width="500">

#### **Three dimensional ultrasound**
  - **Oscillating head probes**: a conventional probe is mounted on a stepper motor, positionally accurate and produce evenly sampled volumes which can be resliced. However they can acquire **only a fixed size, rather small volume**
  <img src="/assets/Capture_nha3tqx20.PNG" width="500">

  - **2D phase array transducers**: A 2D array of crystals steers the beam across a pyramid shaped volume instead of a single B-scan plane, cabling and A/D conversion is difficult
  - **Freehand scanning**: A conventional probe is manually swept over the area of interest, while its position is tracked using either an add on optical tracker or by analyzing the B-scan sequence. The clinician can choose the scanning pattern to best suit the acoustic window, however the position sensor needs careful calibration and poses an interesting re-slicing problem.
  <img src="/assets/Capture_l3j3x5969.PNG" width="500">

### 1.2 Imaging with X-rays
#### **X-ray generation:**
  - The **electrons strike the anode** with energy $E_0$eV where $E_0$ is the potential difference between the anode and the cathode. **Less than 1% of the electron energy goes into the X-rays**.
  - The rest heats the tungsten which has a high melting point, it also usually rotates so the heat can be dissipated more effectively
  ![Capture](/assets/Capture_twaun4o09.PNG)
  - There are two mechanisms for producing X-rays, the breaking radiation and the characteristic radiation. Figure below illustrates the breaking radiation where the electron is decelerated in a discrete number of interactions with the tungsten atoms, releasing a gamma photon at each interaction
  <img src="/assets/Capture_z8bjpb6ey.PNG" width="300">
  - If the incident electron have enough energy to **displace electrons from the inner shell of the tungsten atoms (about 70eV)** additional spectral peaks are observed.
  - The two phenomena are summarized by the picture below
  <img src="/assets/Capture_1z4mj3pyy.PNG" width="400">
  - **Beam hardening** is used in clinical radiology as the superficial absorption of softer photons serves only to distort the output of the imaging system. It is therefore normal to **place a filter of aluminum or copper between the X-ray tube and the subject which reduces the amplitude of soft X-rays.**
#### **X-ray attenuation**
  As a streame of X-ray photons of intensity I and energy E passes through a homogeneous medium of thickness $x$, they are attenuated : $$I = I_0e^{-\mu x}$$
  - **Attenuation through Compton Scattering (undesirable)**
    - Happens when X-ray photons have relatively low energy
    - A photon collides with a weakly bound outer shell electron, which escapes from the atom with some kinetic energy
    - The remaining energy is carried away by a scattered X-ray photon.
    <img src="/assets/Capture_shv60mxuz.PNG" width="400">
  - **Attenuation through Photoelectric absorption (useful)**
    <img src="/assets/Capture_eyvjb0kgz.PNG" width="400">
    - The energy of the X-ray photon is completely absorbed as it ejects an electron from an inner shell.
    - The excess energy of the photon is carried off as kinetic energy by the ejected electron.
    - Lower energy characteristic radiation is emitted in the same direction as the original photon

  Figure below shows the effect of Compton scattering and photoelectric effect
  ![Capture](/assets/Capture_tdk0c9go2.PNG)
  If the attenuation medium compsiese a number of different substances with individual values of $\mu$ the overall attenuation is therefore
  $$I = I_0e^{- \sum_i \mu_i \Delta x_i} = I_0 e^{-\int_{x_0}^{x_1}\mu(x)dx}$$
  For discrete and continuous material respectively.
#### X ray detection
* **Screen-film detector**
  - Emulsion is gelatin in which tiny crystals of silver bromide are suspended
  - **3-10% of the X-ray energy is absorbed by the emulsion**, sensitivity is increased by a factor of 10-40 by intensifying screens
  - The intensifying screen fluoresce when stimulated by X-rays, producing **ultra-violet light**
  - Film has to be developed before the image can be seen
  - **Has to be developed before the image can be seen**
  ![Capture](/assets/Capture_ibq34v9b3.PNG)
- **Scintillation crystal photomultiplier coupled detector**
  - The scintillation material produces **flashes of light** as X-rays are absorbed by Compton Scattering
  - These flashes are **amplified millions of times** to produce a current output
  - The output voltage is proportional to the energy of incoming X-ray photon
  - **Fast, high efficiency but low packing density**, used in current NMR scanners
  ![Capture](/assets/Capture_nrm61c7bf.PNG)

#### X-ray computer tomography
- **Radon Transform**
  - Consider a circle of material defined by $\mu(x,y)$ which we wish to measure. Projection beams defined by the coordinate system $s, l$ which is at an angle $\phi$ relative to the $x,y$ coordinates. We call the intensity profile of the beams **at a angle $\phi$** which gets attenuated by the circle $I_{\phi}(s)$: $$I_\phi (s) = I_0 e^{-\int_{-\infty} ^ {+\infty} \mu(x,y) dl}$$
  ![Capture](/assets/Capture_osw6ungr0.PNG)
  - We can transform the intensity profile into an attenuation profile $p_\phi (s)$ which is the amount absorbed by the material: $$p_\phi (s) = -\ln \dfrac{I_{\phi}(s)}{I_0}$$
  ![2](/assets/2_c910jksc7.PNG)
  - Performing coordinate transform through noting that $$s = \cos(\phi)x + \sin(\phi) y$$ $$l = -\sin(\phi) x + \cos(\phi) y$$
  <img src="/assets/5.PNG" width="300">
  - We can write $$p_\phi (s) = \int_{-\infty}^{\infty} \mu(s\cos\phi - l\sin\phi, s\sin\phi + l\cos\phi)dl$$
  - Now, if we take the full set of projections at different angles, we can stack the resulting $p_\phi(s)$ into a 2D dataset $p(s,\phi)$ called a **sinogram**:
  ![3](/assets/3.PNG)
  - The transform from $\mu(x,y)$ to $p(s, \phi)$ is called the **Radon transform**: $$p(s,\phi) = \mathcal{R}[\mu(x,y)] = \int_{-\infty}^{\infty} \mu(s\cos\phi - l\sin\phi, s\sin\phi + l\cos\phi)dl$$
  - The radon transform maps an image to its projection profiles through all angles, a projection profile is defined by integrating the image along the line of projection
  - For CT reconstruction, we need to find a way of inverting the Radon transform:$$\mu (x,y) = \mathcal{R}^{-1}[p(s,\phi)]$$
- **Inverse Radon Transform Via Fourier Transform**
  - Consider the 1D Fourier transform of the projection data $$\mathcal{F}_1(\omega)[p_\phi(s)] = \int_{-\infty}^{\infty} p_\phi(s) e^{-i\omega s}ds$$ $$ = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \mu(s\cos\phi - l\sin\phi, s\sin\phi + l\cos\phi)e^{-i\omega s}dlds$$
  - Transforming the coordinates from $(s,l)$ to $(x,y)$ (noting Jacobian of transformation is 1) gives $$\mathcal{F}_1(\omega)[p_\phi(s)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \mu(x,y) e^{-i \omega(xcos\phi +y\sin \phi)}dxdy$$
  - The 2D Fourier transform is defined as $$\mathcal{F}[\mu(x,y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \mu(x,y) e^{-i(\omega_x x + \omega_y y)}dxdy $$
  - Comparing the two expressions, we see that $$\mathcal{F}_1(\omega)[p_\phi(s)]  = \mathcal{F}[\mu(x,y)]$$ where $\omega_x = \omega\cos(\phi), \; \omega_y = \omega\sin(\phi)$. In other words, the 1D Fourier transform of the projection data at a given projection angle (a slice in sinogram) is the same as the radial data passing through the origin in the 2D Fourier transform of the attenuation data $\mu(x,y)$
  - Therefore the **Direct Fourier reconstruction** algorithm goes as follows:
    - 1. Take n projections $p_\phi(s)$ of the object
    - 2. Find 1D Fourier transforms of the projections
    - 3. Use the set of 1D Fourier transforms to tile the spatial frequency plane. Each transform contributes a radial strip $(\omega, \phi)$, for a particular angle $\phi$, passing through the origin.
    - 4. Resample this data to produce a regular sampling of the spatial frequency plane
    - 5. Take the 2D inverse Fourier transform
    ![4](/assets/4.PNG)
- Inverse Radon Transform via Filtered Backprojection
  - Direct Fourier reconstruction relies on an accurate 2D interpolation algorithm. Filtered back projection is a way around this problem.
  - Recall $$\mathcal{F}_1(\omega)[p_\phi(s)]  = \mathcal{F}[\mu(x,y)]$$ where $\omega_x = \omega\cos(\phi), \; \omega_y = \omega\sin(\phi)$. Taking the inverse Frouier transform to get to $$\mu(x,y) =  \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}  \mathcal{F}_1(\omega)[p_\phi]e^{i(\omega_x x + \omega_y y)}dxdy $$
  Using the Jacobian transform to write the integral in terms of $(\omega, \phi)$ instead of $(\omega_x, \omega_y)$, where the Jocobian $J = \omega$, therefore the equation above can be written as:
  $$\mu(x,y) =  \int_{0}^{\pi} \int_{-\infty}^{\infty}  \mathcal{F}_1(\omega)[p_\phi] |\omega|e^{i\omega(x \cos\phi+y\sin\phi)}d\omega d\phi$$
- Recall that $s = \cos(\phi)x + \sin(\phi) y$, this means the inner part of the previous equation simplifies to a 1D inverse Fourier transform:
$$\mu(x,y) =  \int_{0}^{\pi}  \{\mathcal{F^{-1} [\mathcal{F}_{1\omega}[p_\phi] |\omega|] }\} d\phi = \int_o^\pi p_\phi(s) * q(s) d\phi$$
Where $q(s) = \mathcal{F}^{-1}[|\omega|]$ and $*$ represents convolution.
- The final algorithm is therefore:
  - Taken n projections $p_\phi(s)$ pf the object
  - Convolve each projection with $q(s)$
  - Backproject each filtered projection in the $l$ direction, notice how $p_\phi(s)*q(s)$ varies only in $s$ direction therefore we can smear the strip out in $l$ direction
  - Accumulate the back projections
- **Summary**
![7](/assets/7.PNG)
- **CT artifacts and Scanning Strategies**
  - Possible reasons for artifacts: **Under-sampling, beam hardening, scattering**
  - **Beam hardening streak artifacts:**
    - This is because the source is actually polychromatic (i.e. containing different X-ray frequencies)
    - High energy photos penetrate into the brain and are attenuated less, so give off low $\mu(x,y)$ which is misinterpreted as dark streaks
    - Can be reduced by placing a beam hardening filter in front of the source
    - **Cupping artifact** due to the fact that the mean photo energy is higher near the tissue exit, leading to a peripherally dense appearance
  - **Scanning strategies**
  First gen: Single X ray detector translated across the object, small rotation each time, 5 min per slice
  Second gen: Multiple detectors, less translation required, 20 seconds per slice
  Third gen: most popular, no translation required, only rotation. 0.5s per slice
  Fourth gen: Only X-ray tube rotates, fixed array of detectors on full circle
  ![6](/assets/6.PNG)

### 1.3 Nuclear Medicine Imaging
NMR is a *functional* imaging modality, which means a molecule is injected in the body and gets involved in some metabolic activity.
**Clinical applications:** bone metabolism, myocardial perfusion and viability, lung embolism, thyroid function and tumors.
- **Emitters**
There are two types of emitters available: **single photon emitters** (used by gamma cameras and SPECT) and **positron emitters** (used by PET)
  - **Single photon emitters:**
    - Most important one is $^{99m}Tc$, which decays to $^{99}Tc$ by emitting a 140keV photon. The half life of the process is 6 hours
    - Hence it benefits from a short half life (good news for patient)
    - It is the made from $^{99}Mo$ which has a half life of 66 hours so no need for in house cyclotron
    - 140keV is pretty ideal as it is enough to leave the body but absorbed by the scintillation crystals
    - **They are heavy** therefore cannot be found in organic molecules, so it has to be grafted on
  - **Positron Emitters**
    - $^{18}F$ with a 109 minutes half life is a good example, the positron it emits survives for nanoseconds and travel a few millimeters before it encounters an electron
    - The two demolish each other, their combined mass is released into pure energy with a form of 511keV photons
    - These positron emitters are **light** therefore can be incorporated within organic molecules without changing their chemical characteristics
    - They need to be **produced in hospital located cyclotrons**

- **Detectors**
  - **Comparision with X-ray CT**
    - Count rates are lower, so detector optimized for sensitivity not speed
    - Detector needs to measure energy as well as the number of the incoming photons
    - Location of the source is unknown so the detectors require collimation
    ![8](/assets/8.PNG)
   - **Collimation**
      Therefore, a collimator is essential to filter out photons from other directions. When a photon is detected we know, to a certain accuracy, the line on which the source must lie.
      ![9](/assets/9.PNG)
  - **Gamma Camera**
    - Issue with the collimators is that they absorb the vast majority of the emitted photons
    - This reduces the imaging sensitivity
    - A gamma camera is used to image single photon emitting radionuclides, it contains a single large scintillation crystal, a collimator and photomultiplier tubes
    - Due to Compton scattering, by the time the light reaches the PMT array, it is sufficiently spread out to register many PMTs. The scintillation lasts around 300ns. So each PMT output $s_i(t)$ is integrated to ensure that the total energy is registered: $$S_i = \int_{t_o}^{t_0 +300ns}s_i(t)dt$$
    - The $x, y$ position of the incoming photon is then: $$x = \dfrac{\sum_i x_iS_i}{\sum_i S_i} \qquad y = \dfrac{\sum_i y_iS_i}{\sum_i S_i}$$
  - **Resolution:**
  Overall resolution is limited by **intrinsic resolution, collimator resolution and Compton scattering (within the paitient)**
  **Intrinsic resolution**: Because of the approximate $(x,y)$ calculation, the intrinsic resolution is only 3-5mm
  **Collimator resolution:** Given by $R_c = \dfrac{2bd}{l} + d$ through simple geometry:
  ![1](/assets/1.PNG)

  - **Energy Filtering**
  To further filter results collected by the PMT, energy filtering is applied. Since with $^{99m}Tc$ we expect a total of around 140keV to be absorbed by PMTs, the z-signal can be calculated: $z = \sum_i S_i$, which is a measure of the incoming photon energy
  If $z < z_{min}$ then the photon is due to Compton scatter inside the patient and is rejected
  If $z > z_{max}$ then the PMTs are recording two almost simultaneous events which must also be rejected

  - **Issues with Planar Imaging**
  Just like X-ray imaging, the depth information is completely lost!
  What the PMTs measure is actually the attenuated activity of the photons, not the activity itself!

  - **SPECT scanners**
  Solution to loss of depth information: perform reconstruction from many planar images!
  Acquisition time can be reduced by mounting multiple cameras on the gantry

  - **PET scanners**
    - Positron Emission Tomography is much more sensitive than SPECT, but requires an onsite cyclotron
    - PET scanners have **parallel rings of small detector modules** instead of a large single detector.
    - Scintillation crystal inside the detectors is bismuth germanate (**BGO**) which is responsive to 511keV annihilation photons.
    - Typically comprise a **small array of BGO crystals** connected to an array of PMTs
    - **Conputation of impact location ($x,y$) and energy $z$** proceeds as with photon emission
    - However, as shown later, multiple photons can be detected at the same time by different modules (no need for energy filtering)
    - **Uses electronic collimation** instead of a mechanical collimator, this is because **both photons** from an annihilation event are detected by the PMT array. The line of projection is therefore the line linking these two events, and it is only registered if the two photons are detected within 10ns of each other. ![2.2](/assets/2.2.PNG)
    - The right picture depicts the possible line of projections for only two nodes. Showing how good PET sensitivity is compared with SPECT!
    - If two photons hit the same module within 300ns scintillation time, they are rejected (does not happen often in 2D mode)
  - **3D PET Scanners**
    - Note that PET scanners are **inherently 3D** meaning that with a cylinder of detectors, the lines of projection naturally span across the entire 3D space!
    - However it is more easy (see below) to operate in 2D mode, therefore septa are deployed, discarding the majority of the photon pairs (left picture) ![1](/assets/1_4f778k17e.PNG)
    - If operating in 3D, then full 3D reconstruction algorithms are required, it is also more difficult to achieve high count rates
    - Also, more multiple pair rejections will occur as there are more two photons hitting the array within the 10ns window.
  - **Attenuation Correction with CT**
    - From tracer to detector, the photons are attenuated by photoelectric absorption and Compton scattering.
    - We therefore need to correct for the attenuation, the theoretical detected number of photons from a source $a$ at distances $d_1, d_2$ from the detectors (shown below) is $$N(d_1, d_2) = \lambda (a) \exp [-\int_{d_1}^{a}\mu(s)ds]\exp[-\int_a^{d_2} \mu (s)ds] = \lambda (a) \exp [-\int_{d_1}^{d_2}\mu (s)ds]$$
    ![1](/assets/1_y4zoo1276.PNG)
    - Note the equation above is the exact thing we measure from a CT scanner, reconstructing the CT data provides the PET attenuation correction factors $\exp[-\int_{d_1}^{d_2}\mu (s)ds]$

- **2D Iterative Reconstruction**
  - Tomographic reconstruction can be used to find $\mu (x,y)$ (attenuation data) at every point in the body. This information can then be fed into an iterative algorithm to recover $\lambda(x,y)$ (emission data).
  - Iterative reconstruction is also used for PET, since it is better than filtered back projection at dealing with Poisson noise
  - **Algebraic reconstruction technique**
    - Given the noisy measurements of $I$ attenuated projections $r_i$, and the projection matrix $C$, we wish to recover the radioactivity $\lambda_j$ for each $j$ in $J=n\times n$ pixels.
    - The relationship between the projection slice $r_i$ and $\lambda_j$ through the projection matrix $C$ is denoted as: $$r_i = \sum_{j=1}^J c_{ij}\lambda_j \;\; , \;\; i = 1...![]()$$![4](/assets/4_63njdyviy.PNG)
    - We use $c_{ij}$ values to account for attenuation. For SPECT, $c_{ij}$ will be known from tomographic reconstruction. For PET, attenuation factor is the same for each pixel along the projection line $i$
    - **Additive ART**: Average error added to eacg pixel value
      - To ensure convergence, it is usual to include a relaxation term: in successive iterations the pixels are corrected by an ever decreasing fraction of the amount needed to satisfy each projection
      - Update formula for $k+1$th iteration: $$\lambda_j^{(k+1)} = \lambda_j^{(k)} + \dfrac{\beta^{(k)}}{N}\left(r_i - \sum_{i=1}^N \lambda_i^{(k)}\right)$$
      - $N$ is the number of pixels contribution to the projection, the above formula states: the next iteration value is equal to **the current pixel value plus the average error made through projecting current values in the projection direction, multiplied by a relaxation constant**, below shows a hand worked example for $\beta=1$:
      ![1](/assets/1_fbpi3ezvr.PNG)
  - **AART** does not take into account of Poisson measurement noise, the Maximum likelihood expectation maximization (ML-EM) algorithm attempts to do so but is not completely successful. There are several work-arounds:
    - Smooth the reconstructed image
    - Find the MAP solution as it favors a smooth solution by including a prior
    - Interrupt the EM algorithm before it has converged. ML-EM has a property that low frequencies converge faster
### 1.4 Magnetic Resonance Imaging
- **Advantages & Disadvantages:**
  - Non-hazardous, patient not exposed to ionizing radiations
  - High definition, high quality image
  - Gives better contrast between different soft tissues than CT
  - Not so good with bone and air (low water content), so CT preferred for the skeleton, calcifications and lungs
  - Inherently slower effect than X-rays so longer imaging time
  - Very expensive
-  **Basic Principles:**
    - General setup: A constant, very strong magnetic field providing the alignment axis, gradient coils used to generate non-uniform magnetic fields. RF coils to produce pulses of magnetic fields. ![1](/assets/1_7nnnf2lep.PNG)
    - **Hydrogen** contains an odd number of protons (one) therefore it possess nuclear spin and hence a magnetic moment along the spin axis.
    - When a strong external magnetic field $B_0$ around several Tesla is applied along the $z$ axis, the hydrogen atoms **precess** around the $z$ axis, much like a gyroscope.
- $TE$ is the amount of time the scanner waits after the spin excitation to detect the signal, $TR$ is the amount of time the scanner waits in between excitations

## 2. Surface Representations
### 2.1 Polygon Meshes Representations
* **Vertex List**
  - Each vertex is a tuple of coordinates
  - Each polygon is a list of vertices
  ![2](/assets/2_mzq35lvft.PNG)

  - Still difficult to **find polygons that share an edge**
  - **Shared edges are rendered twice**
- **Edge List representation**
  - Each vertex is a tuple of coordinates
  - Each edge is a list of spanning vertices and polygons they belong to
  - Each polygon is a list of edges
  ![2](/assets/2_dg5gn2x0r.PNG)
  - Shared edges are no longer drawn twice
  - At the expense of extra storage
- **Consistency of polygon meshes**
  - Closed and Planar
  - Ordering of vertices are consistant
  - Each vertex is referenced by at least two edges
  - Edges are not used multiple times in the same polygon
  - Polygons do not self intersect
- **Polygon normals**
  - As polygons may not be perfectly planar, a more robust approach (other than cross product of edges) is to find a plane which comes close to all vertices: $$Ax+By+Cz+D=0$$
  - $A,B,C$ represent the area of triangle through polygon projection onto the $y-z, \; x-z. \; x-y$ planes respectively.
  - These areas of projections can be found through the equations:
  ![3](/assets/3_9nyo7xknz.PNG)
  - Figure below illustrates how $C$ may be found, note these projection area coefficients are found through adding/subtracting trapeziums, the projection onto $x-y$ plane is trivial (just ditch the $z$ coordinate). $$C = \dfrac{1}{2}[(y_1 +y_2)(x_1 - x_2)+(y_2 +y_3)(x_2 - x_3)+(y_3 + y_1)(x_3 - x_1)]$$
  - Can be written in terms of area of the trapezium: $$C = -(1) + (3) - (2)$$![4](/assets/4_qgmh3qn5h.PNG)
  - This works because the vertices have been enumerated in an anticlockwise order, the projection areas are therefore all positive. $D$ is determined by inserting a particular vertex into the plane's equation.
### 2.2 Parametric Representations of Curves
#### Formulation and Continuity
- Problems with explicit and implicit representations of curves:
  - Explicit representation $y=f(x)$, $z = g(x)$: impossible to get multiple values of $y$ or $z$ for a single $x$, also not rotatinally invariant, rotating a curve requires a lot of maths
  - Implicit representation: $f(x,y,z)=0$ difficult to represent segments like half a circle
- **Cubic polynomials parametric equations** are ideal for $x(t), y(t), z(t)$
- In matrix form we have $$\bm{Q}(t) = \bm{T}C$$
  $$[x(t)\; y(t)\; z(t)] = [t^3\;t^2\;t\;1]\begin{bmatrix}
a_x & a_y & a_z \\
b_x & b_y & b_z \\
c_x & c_y & c_z \\
d_x & d_y & d_z
\end{bmatrix}  $$
With the tangent vector (can be thought of as parametric velocity) being $$\bm{Q'}(t)=[3t^2\;2t\;1\;0]C$$
We can also write $\bm{Q}(t)$ in the form of $$\bm{Q}(t) = \bm{T}MG$$ where $C=MG$, here $M$ is the basis matrix (fixed for different parametric representations below) and $G$ is the geometric constraint matrix (user specified, different for different curves)
- **Continuity issues**:
  <img src="/assets/1_45snfmig5.PNG" width="350">   <img src="/assets/11.PNG" width="330">
  - $C^1$ continuity normally implies $G^1$ continuity

#### Hermite Representations
Constrained by four points, two end point position vectors and two end point tangent vectors, in order to satisfy these constraints (recall that $t$ ranges from 0 to 1):
![1](/assets/1_5pcw7invp.PNG)
Recall $$\bm{Q}(t) = [t^3\;t^2\;t\;1] C\qquad \bm{Q'}(t)=[3t^2\;2t\;1\;0]C $$ substituting constraints in, we obtain $$\begin{bmatrix}
0 & 0 & 0 & 1 \\
1 & 1 & 1 & 1 \\
0 & 0 & 1 & 0 \\
3 & 2 & 1 & 0
\end{bmatrix}  C =  \begin{bmatrix}
\bm{P_1} \\
\bm{P_4} \\
\bm{R_1} \\
\bm{R_4}
\end{bmatrix}$$
Hence $$C = \begin{bmatrix}
2 & -2 & 1 & 1 \\
-3 & 3 & -2 & -1 \\
0 & 0 & 1 & 0 \\
1 & 0 & 0 & 0
\end{bmatrix}   \begin{bmatrix}
\bm{P_1} \\
\bm{P_4} \\
\bm{R_1} \\
\bm{R_4}
\end{bmatrix} = M_h G_h$$
To join two Hermite curves is simple, from the diagram below, the constraint matrices can be worked out:
![1](/assets/1_6cm9m4df6.PNG)
$$C_1 = \begin{bmatrix}
\bm{P_1} \\
\bm{P_4} \\
\bm{R_1} \\
\bm{R_4}
\end{bmatrix} \qquad C_2= \begin{bmatrix}
\bm{P_4} \\
\bm{P_7} \\
k\bm{R_4} \\
\bm{R_7}
\end{bmatrix}$$
#### Bazier Representation
![1](/assets/1_07w2jn3c6.PNG)
Very similar to Hermite, only instead of the tangent vectors, we replace them with $\bm{P_2}, \bm{P_3}$, recall in Hermite form $\bm{Q}(t) = \bm{T}M_h G_h$, to convert to Bazier representation, a transformation matrix is required: $$G_h = \begin{bmatrix}
\bm{P_1} \\
\bm{P_4} \\
\bm{R_1} \\
\bm{R_4}
\end{bmatrix} = \begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 \\
-3 & 3 & 0 & 0 \\
0 & 0 & -3 & 3
\end{bmatrix} \begin{bmatrix}
\bm{P_1} \\
\bm{P_2} \\
\bm{P_3} \\
\bm{P_4}
\end{bmatrix} $$
The 3 terms are necessary to ensure that $\bm{Q'}(t)$ is constant for four collinear, regularly spaced control points. Hence $$C = M_h G_h = M_h \begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 \\
-3 & 3 & 0 & 0 \\
0 & 0 & -3 & 3
\end{bmatrix} \begin{bmatrix}
\bm{P_1} \\
\bm{P_2} \\
\bm{P_3} \\
\bm{P_4}
\end{bmatrix}  =  \begin{bmatrix}
-1 & 3 & -3 & 1 \\
3 & -6 & 3 & 0 \\
-3 & 3 & 0 & 0 \\
1 & 0 & 0 & 0
\end{bmatrix} \begin{bmatrix}
\bm{P_1} \\
\bm{P_2} \\
\bm{P_3} \\
\bm{P_4}
\end{bmatrix} = M_bG_b$$
In order to join two segments of Bazier curves and maintain $G_1$ continuity (same tangent vector) we have $$\bm{P_5}-\bm{P_4} = k(\bm{P_4}-\bm{P_3})$$
With $k=1$ implying $C_1$ continuity
![Capture](/assets/Capture_pjv41vebm.PNG)
**Bazier corve lies within the convex hull** of its four control points, a point which lies within the convex hull can be written as a linear sum of the points with the weights all lying between 0 and 1.

#### B-Splines and Catmull-Rom Splines
Splines are used to approximate or interpolate points in space. Consider the B-splines:
![1](/assets/1_3nlpv8z0r.PNG)
Each spline segment $i$ is represented as $\bm{Q_i}(t) = \bm{T}M_sG_{si}$, the geometry matrix $G_{s}$ consists of four control points: $$ G_s = \begin{bmatrix}
\bm{P_0} \\
\bm{P_1} \\
\bm{P_2} \\
\bm{P_3}
\end{bmatrix}$$
To achieve $C_2$ continuity between segments, the successive control points can be chosen as $$ G_{s1} = \begin{bmatrix}
\bm{P_0} \\
\bm{P_1} \\
\bm{P_2} \\
\bm{P_3}
\end{bmatrix} \quad G_{s2} = \begin{bmatrix}
\bm{P_1} \\
\bm{P_2} \\
\bm{P_3} \\
\bm{P_4}
\end{bmatrix} \quad G_{si} = \begin{bmatrix}
\bm{P_{i-1}} \\
\bm{P_{i}} \\
\bm{P_{i+1}} \\
\bm{P_{i+2}}
\end{bmatrix}$$
So $n$ control points define $n-3$ spline segments.
**B-splines** do not generally pass through control points, they are seen as a form of **approximation** between points, consider **Catmull-Rom** splines, which exhibits $C^1$ continuity but does not possess the convex hull property. The endpoints of segment $Q_i$ are the control points $\bm{P_i}$ and $\bm{P_{i+1}}$. This interpolates between points.![1](/assets/1_4d0tprxwx.PNG)

To determine which form to use when rendering curves from datapoints, we use the following table: ![Capture](/assets/Capture_a8u9tek9j.PNG)
### 2.3 Bicubic Surface Patches
Surface patches can be generated by making the geometrix matrix a function of another parameter, first we replace $t$ with $s$ for notational convenience, hence $$\bm{Q}(s,t) = \bm{S}MG(t)$$
Where $\bm{S} = [s^3\;s^2\;s\; 1]$ and $G(t)$ provides four parametric curves defining the surface boundaries.![Capture](/assets/Capture_llxd3st2d.PNG)
We can split $\bm{Q}(s,t) = \bm{S}MG(t)$ into separate $x,y,z$ coordinates:
$$[x(s,t) \; y(s,t) \; z(s,t)] = \bm{S}M[\bm{G_x(t)}\; \bm{G_y(t)}\; \bm{G_z(t)}]$$
By just investigating $x(s,t) = \bm{S}M\bm{G_x(t)}$, we represent the four elements in $\bm{G_x}$ as four cubic paths as $t$ varies:
$$\bm{G}_x^T = \bm{T}MQ_x^T$$
For a Hermite patch, the meaning of the geometric matrix $Q_x$ is shown below, derivation shown in handout:
![Capture](/assets/Capture_y14ll2mju.PNG)
Therefore, these geometric matricies encode the positions of the patch's corners, the tangent vectors at the corners in $s,t$ direction and also the **twists** at the corners.
Hermite patches can be joined with $C^1$ continuity if the positions, tangents and twists of the shared edges are identical :
![Capture](/assets/Capture_xfokq968h.PNG)![Capture](/assets/Capture_uzbnb4nz1.PNG)
### 2.4 Surface normals
Recall that $\bm{Q}(s,t) = [x(s,t) \;y(s,t)\;z(s,t)]$ the normal of the surface can be calculated as the cross product between the gradients:
$$\bm{n} = \dfrac{\partial \bm{Q}}{\partial s} \times  \dfrac{\partial \bm{Q}}{\partial t} = (\dfrac{\partial x}{\partial s},\dfrac{\partial y}{\partial s},\dfrac{\partial x}{\partial s}) \times (\dfrac{\partial x}{\partial t},\dfrac{\partial y}{\partial t},\dfrac{\partial x}{\partial t})$$ 
where $$x(s,t) = \bm{S}MQ_xM^T\bm{T}^T$$
$$\dfrac{\partial x}{\partial s} = [3s^2 \;2s\; 1\; 0]MQ_xM^T\bm{T}^T$$
$$\dfrac{\partial x}{\partial t} = \bm{S}MQ_xM^T[3t^2\;2t\;1\;0]^T$$
